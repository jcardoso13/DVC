\begin{thebibliography}{21}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Piccinini(2004)]{neuron:model}
G.~Piccinini.
\newblock The first computational theory of mind and brain: A close look at
  mcculloch and pitts's “logical calculus of ideas immanent in nervous
  activity”.
\newblock \emph{Synthese}, 141, 08 2004.
\newblock \doi{10.1023/B:SYNT.0000043018.52445.3e}.

\bibitem[LeCun et~al.(2015)LeCun, Bengio, and Hinton]{deeplearning}
Y.~LeCun, Y.~Bengio, and G.~Hinton.
\newblock Deep learning.
\newblock \emph{Nature}, 521:\penalty0 436--44, 05 2015.
\newblock \doi{10.1038/nature14539}.

\bibitem[Leshno et~al.(1993)Leshno, Lin, Pinkus, and
  Schocken]{approximation:problem}
M.~Leshno, V.~Y. Lin, A.~Pinkus, and S.~Schocken.
\newblock Multilayer feedforward networks with a nonpolynomial activation
  function can approximate any function.
\newblock \emph{Neural Networks}, 6\penalty0 (6):\penalty0 861 -- 867, 1993.
\newblock ISSN 0893-6080.
\newblock \doi{https://doi.org/10.1016/S0893-6080(05)80131-5}.
\newblock URL
  \url{http://www.sciencedirect.com/science/article/pii/S0893608005801315}.

\bibitem[mni()]{mnist:digits}
mnist database of hand-written digits.
\newblock URL \url{http://yann.lecun.com/exdb/mnist/}.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{alexnet}
A.~Krizhevsky, I.~Sutskever, and G.~E. Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock In \emph{Advances in Neural Information Processing Systems 25}, pages
  1097--1105. 2012.

\bibitem[He et~al.(2015)He, Zhang, Ren, and Sun]{resnet}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition, 2015.

\bibitem[Redmon and Farhadi(2018)]{yolov3}
J.~Redmon and A.~Farhadi.
\newblock Yolov3: An incremental improvement, 2018.

\bibitem[Srivastava et~al.(2014)Srivastava, Hinton, Krizhevsky, Sutskever, and
  Salakhutdinov]{Dropout}
N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov.
\newblock Dropout: A simple way to prevent neural networks from overfitting.
\newblock \emph{Journal of Machine Learning Research}, 15:\penalty0 1929--1958,
  2014.

\bibitem[Redmon(2013--2016)]{darknet}
J.~Redmon.
\newblock Darknet: Open source neural networks in c.
\newblock \url{http://pjreddie.com/darknet/}, 2013--2016.

\bibitem[Jia et~al.(2014)Jia, Shelhamer, Donahue, Karayev, Long, Girshick,
  Guadarrama, and Darrell]{caffe}
Y.~Jia, E.~Shelhamer, J.~Donahue, S.~Karayev, J.~Long, R.~B. Girshick,
  S.~Guadarrama, and T.~Darrell.
\newblock Caffe: Convolutional architecture for fast feature embedding.
\newblock \emph{CoRR}, abs/1408.5093, 2014.
\newblock URL \url{http://arxiv.org/abs/1408.5093}.

\bibitem[Santiago et~al.(2017)Santiago, Lopes, and de~Sousa]{sousa:compiler}
R.~Santiago, J.~D. Lopes, and J.~T. de~Sousa.
\newblock Compiler for the versat reconfigurable architecture.
\newblock REC 2017, 2017.

\bibitem[Lopes et~al.(2016)Lopes, Santiago, and de~Sousa]{sousa:controller}
J.~D. Lopes, R.~Santiago, and J.~T. de~Sousa.
\newblock Versat, a runtime partially reconfigurable coarse-grain
  reconfigurable array using a programmable controller.
\newblock Jornadas Sarteco, 2016.

\bibitem[Lopes and de~Sousa(2017)]{sousa:FFT}
J.~D. Lopes and J.~T. de~Sousa.
\newblock Fast fourier transform on the versat cgra.
\newblock Jornadas Sarteco, 09 2017.

\bibitem[Lopes and de~Sousa(2016)]{sousa:versat2016}
J.~D. Lopes and J.~T. de~Sousa.
\newblock Versat, a minimal coarse-grain reconfigurable array.
\newblock In D.~I., C.~R., B.~J., and M.~O., editors, \emph{High Performance
  Computing for Computational Science – VECPAR 2016}, pages 174--187.
  Springer, 2016.
\newblock doi:10.1007/978-3-319-61982-8\_17.

\bibitem[Lopes(2017)]{lopes:versat}
J.~D. Lopes.
\newblock Versat, a compile-friendly reconfigurable processor – architecture.
\newblock Master's thesis, Instituto Superior Técnico, November 2017.

\bibitem[Mário(2019)]{valter:deepversat}
V.~J.~B. Mário.
\newblock Deep versat: A deep coarse grain reconfigurable array.
\newblock Master's thesis, Instituto Superior Técnico, November 2019.

\bibitem[pic()]{picorv}
Picorv32- a size-optimized risc-v cpu.
\newblock URL \url{https://github.com/cliffordwolf/picorv32}.

\bibitem[Ignatov et~al.(2018)Ignatov, Timofte, Szczepaniak, Chou, Wang, Wu,
  Hartley, and Van~Gool]{smartphones}
A.~Ignatov, R.~Timofte, P.~Szczepaniak, W.~Chou, K.~Wang, M.~Wu, T.~Hartley,
  and L.~Van~Gool.
\newblock Ai benchmark: Running deep neural networks on android smartphones, 10
  2018.

\bibitem[Venieris et~al.(2018)Venieris, Kouris, and Bouganis]{misc:cnntofpga}
S.~I. Venieris, A.~Kouris, and C.-S. Bouganis.
\newblock Toolflows for mapping convolutional neural networks on fpgas: A
  survey and future directions, 2018.

\bibitem[Venieris and Bouganis(2016)]{fpgaconvnet}
S.~I. Venieris and C.-S. Bouganis.
\newblock {fpgaConvNet: A Framework for Mapping Convolutional Neural Networks
  on FPGAs}.
\newblock In \emph{2016 {IEEE} 24th Annual International Symposium on
  Field-Programmable Custom Computing Machines ({FCCM})}, pages 40--47.
  Institute of Electrical and Electronics Engineers ({IEEE}), May 2016.
\newblock \doi{10.1109/FCCM.2016.22}.
\newblock URL \url{http://dx.doi.org/10.1109/FCCM.2016.22}.

\bibitem[Bae et~al.(2018)Bae, Harris, Min, and Egger]{cgraopt}
I.~Bae, B.~Harris, H.~Min, and B.~Egger.
\newblock Auto-tuning cnns for coarse-grained reconfigurable array-based
  accelerators.
\newblock \emph{IEEE Transactions on Computer-Aided Design of Integrated
  Circuits and Systems}, 37, 07 2018.
\newblock \doi{10.1109/TCAD.2018.2857278}.

\end{thebibliography}
