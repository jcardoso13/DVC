%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                      %
%     File: Thesis_Introduction.tex                                    %
%     Tex Master: Thesis.tex                                           %
%                                                                      %
%     Author: Andre C. Marta                                           %
%     Last modified:  2 Jul 2015                                      %
%                                                                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{chapter:introduction}




In this thesis, the problem of accelerating the execution of Deep Neural
Networks (DNNs) using Coarse-Grained Reconfigurable Arrays (CGRAs) are studied,
with special emphasis on compiling a DNN description into code that runs on
CPU/CGRA system. The DeepVersat Architecture~\cite{valter:deepversat} CGRA is used as an
implementation tool in this work.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motivation}
\label{section:motivation}

Neural Networks have been an object of study since the 1940s but until the
beginning of this decade their applications were limited and did not play a
major role in computer vision conferences. With its meteoric rise in research,
several solutions to accelerate this algorithm have appeared, from Field Programmable Gate Arrays (FPGA) to
Application Specific Integrated Circuits (ASIC) implementations.

Convolutional Neural Networks (CNNs) are a particular kind of DNN where the output
values of the neurons in one layer are convolved with a kernel to produce the
input values of the neurons of the next layer. This algorithm is compute bound,
that is, its performance depends on how fast it can do certain calculations, and
depend less on the memory access time. Namely, the convolutional layers take
approximately 90$\%$ of the computation time.

The acceleration of these workloads is a matter of importance for today's
applications such as image processing for object recognition or simply to
enhance certain images. Other uses like instant translation and virtual
assistants are applications of neural networks and their acceleration is of
vital importance to bring them into the Internet of Things.

A suitable circuit to accelerate DNNs in hardware is the CGRA. A CGRA is a
collection of Functional Units and memories with programmable interconnections
to form computational datapaths. A CGRA can be implemented in both
FPGAs and ASICs. CGRAs can be reconfigured much faster than FPGAs, as they have
much fewer configuration bits. If reconfiguration is done at runtime, CGRAs add
temporal scalability to the spacial scalability that characterizes
FPGAs. Moreover, partial reconfiguration is much easier to do in CGRAs compared
to FPGAs which further speeds up reconfiguration time. Another advantage of
CGRAs are the fact that they can be programmed entirely in software, contrasting
with the large development time of customized Intellectual Property (IP) blocks.
The Coarse Grain Reconfigurable Array (CGRA) is a midway acceleration solution
between FPGAs, which are flexible but large, power-hungry, and difficult to
reprogram, and ASICs, which are fast but generally not programmable.

However, mapping a specific DNN to a CGRA requires knowledge of its
architecture, latencies, and register configurations, which may become a lengthy
process, especially if the user wants to explore the design space for several
DNN configurations. An automatic compiler that can map a standard DNN
description into CPU/CGRA code would dramatically decrease the time to market of its
users. Currently, there are equivalent tools for CPUs and GPUs and
even for FPGAs.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Objetive}
\label{section:objetctive}

The main objective of this thesis is to take an established Neural Network Framework, in this case
Darknet\cite{Darknet}. A tool will transform a prototype machine learning model file created for Caffe into CFG files
which are read by Darknet, so if a user has a DNN in Caffe, it can be used by the system.
Afterward, the CFG file can be parsed by the tool to create the layer and data structures
needed for Darknet.

The Versat CGRA is the DNN accelerator to improve the performance of the DNNs in embedded hardware.
This work presents a software simulator for Versat so the development can be simultaneous and
to write the configurations of said hardware.
Another objective is to increase the versatility of the Versat API and offer new functions
to simplify the development of new software. One of these functions is a generic convolution for
Versat which can, independently of the hardware configuration, configure the convolution to have
the highest performance possible on the available functional units while being dynamic and
to avoid developer work to adapt to new convolutions.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Thesis Outline}
%\label{section:outline}

%Briefly explain the contents of the different chapters...

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Author's Work}
%\label{section:authorwork}

%TO ADD----

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Thesis Outline}
\label{reportoutline}

The document has the following chapters:

\begin{itemize}
	\item Chapter 2 introduces the background needed to understand the work presented in other 
chapters relating to neural networks and the Versat CGRA.
	\item Chapter 3 describes the Darknet framework and its embedded implementation, the tool
to transform Caffe to CFG and to transform CFG to C++ code with the layers and data structures needed
	\item Chapter 4 talks about the DeepVersat Simulator and how the simulator structure 
and architecture is designed and implemented.
	\item Chapter 5 explains the new functions that the Versat API has that are used for
development
	\item Chapter 6 presents the results of the work explained in the previous chapters as well
and the expected performance that the Versat CGRA has with several convolutions using the
simulator.
	\item Chapter 7 is the final remarks of this thesis, explains the shortcomings and what's missing
from this thesis and possible future work.
  \end{itemize}


